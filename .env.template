# Environment Configuration Template

# Copy this file to .env and customize as needed
# Load with: export $(cat .env | xargs)

# ==================== Index Configuration ====================

# Directory for storing search indices (default: .index)
INDEX_DIR=.index

# Embedding model to use
# Options:
#   - BAAI/bge-small-en (default, good balance)
#   - sentence-transformers/all-MiniLM-L6-v2 (faster, smaller)
#   - sentence-transformers/all-mpnet-base-v2 (better quality, slower)
#   - nomic-embed-text (if using Ollama)
EMBEDDING_MODEL=BAAI/bge-small-en

# ==================== Hybrid Scoring Weights ====================

# Weight for BM25 keyword matching (0-1, default 0.6)
# Higher = more keyword-focused
BM25_WEIGHT=0.6

# Weight for semantic similarity (0-1, default 0.4)
# Higher = more meaning-focused
SEMANTIC_WEIGHT=0.4

# Note: BM25_WEIGHT + SEMANTIC_WEIGHT should equal 1.0

# ==================== Chunking Configuration ====================

# Target chunk size in tokens (default 400)
# ~300 words for prose, adjusted for code
CHUNK_SIZE_TOKENS=400

# Overlap between chunks in words (default 50)
CHUNK_OVERLAP_WORDS=50

# ==================== Fusion Method ====================

# Method for combining scores (default: weighted)
# Options: weighted, rrf (reciprocal rank fusion)
FUSION_METHOD=weighted

# ==================== Performance Tuning ====================

# For faster indexing, use smaller model:
# EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# For better semantic search, use larger model:
# EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2

# For more keyword-focused search (technical docs):
# BM25_WEIGHT=0.7
# SEMANTIC_WEIGHT=0.3

# For more semantic search (conceptual queries):
# BM25_WEIGHT=0.5
# SEMANTIC_WEIGHT=0.5

# ==================== Ollama Configuration (Optional) ====================

# If using Ollama for embeddings:
# EMBEDDING_MODEL=nomic-embed-text
# Make sure Ollama is running: ollama serve
